# HW_DL
Домашние задания по Глубокому обучению

## Перевод документации MATLAB
### Переводить страницы с документацией MATLAB
Размер датасета  ~ 15к
#### Выбор модели 
Google translate API не очень хорошо заработал на этих данных, поэтому решил дообучить готовую модель перевода.
На выбор из преобученных было 2 Helsinki-NLP/opus-mt-en-ru и facebook/wmt19-ru-en.
Модель от facebook не очень хорошо заработала, поэтому продолжил работать с Helsinki-NLP/opus-mt-en-ru.
Поначалу пробовал обучать только последние слои но это работало значительно хуже чем обучение всей сети. К сожалению на этом этаме я резульаты не логировал, но они были примерно такие facebook: ~33, HelsinkiNLP: ~55 по BLEU, после примерно 10 эпох.

#### Подбор пармаметров
Для подбора праметров обучения воспользовался втсроенными инструментами wandb. Оптимизировал batch_size, learning rate, алгоритм оптимизации.
Сейчас BLEU~66,5 после 20 эпох обучения. 
Есть мысль обучить это в RL режиме как в статье https://aclanthology.org/D18-1397/

#### Данные
Данные были дополненены до 30k парсингом сайта с документацией Python.

#### Что пока получилось
В табличке примеры работы обученной модели (средняя колонка) и Google API (крайняя правая колонка)
![image](https://user-images.githubusercontent.com/55480570/171221389-c31284c9-6cf5-4c16-bfc6-d3d9b296d362.png)


код: https://github.com/kalnin-a-i/translator
wandb: https://wandb.ai/a-i-kalinin/translator?workspace=user-a-i-kalinin

## Deep Q-learning для LunarLander
Ноутбук с кодом ледит в этом репозитории

Изначально реализовал ванильный Q-learning без replay-buffer, но нчего так и не сошлось. Дописал ReplayBuffer и дела пошли на лад. Ракета садиться.

По поводу выбора алгортима ничего написать не могу просто хотел поиграть.
Параметры обучения подбирал часть наугад часть из статей.


